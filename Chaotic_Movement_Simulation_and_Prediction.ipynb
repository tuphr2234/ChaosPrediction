{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuphr2234/ChaosPrediction/blob/main/Chaotic_Movement_Simulation_and_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OnUDSnDpNv_"
      },
      "source": [
        "## Anvil Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVWGJlK2mPuW"
      },
      "source": [
        "Install Anvil uplink connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRACjTilpV7-"
      },
      "outputs": [],
      "source": [
        "!pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N-1YxoVpab9"
      },
      "source": [
        "Connect Colab with the Anvil project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "u3OYcJSTpRt0"
      },
      "outputs": [],
      "source": [
        "import anvil.server\n",
        "anvil.server.connect(\"M2SHTQKH2FUIJQQXXX4VKXEB-I37SIP4DTE6Z5NM3\") # <----- [insert your anvil uplink here]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxmjpJhlome2"
      },
      "source": [
        "## Simulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gb6t4nkR13k"
      },
      "outputs": [],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnrjXTFS_WBT"
      },
      "source": [
        "### N-Body Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGciHyE3p8Ac"
      },
      "source": [
        "#### The Body Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kVyapbdnp7sv"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "\n",
        "G=1 # gravitational force\n",
        "@anvil.server.callable\n",
        "class Body:\n",
        "  # variables\n",
        "  prevPosition = np.array([0,0])\n",
        "  position = np.array([0,0])\n",
        "  velocity = np.array([0,0])\n",
        "  force = np.array([0,0])\n",
        "  acceleration = np.array([0,0])\n",
        "  mass = 0\n",
        "\n",
        "  # constructor\n",
        "  def __init__(self,position=[0,0],velocity=[0,0],mass=1,name=\"newBody\"):\n",
        "    self.position=np.array(position)\n",
        "    self.velocity=np.array(velocity)\n",
        "    #self.acceleration=np.array(acceleration)\n",
        "    self.mass=mass\n",
        "    self.prevPosition=np.array(position)\n",
        "    self.name = name\n",
        "\n",
        "  # set initial position\n",
        "  def setInitialPostion(self,position):\n",
        "    self.postion = np.array(position)\n",
        "    self.prevPosition=np.array(position)\n",
        "\n",
        "  # set initial velocity\n",
        "  def setInitialVelocity(self,velocity):\n",
        "    self.velocity = np.array(velocity)\n",
        "\n",
        "  # set initial mass\n",
        "  def setInitialMass(self,mass):\n",
        "    self.mass = mass\n",
        "\n",
        "  # update position\n",
        "  def setPosition(self,t):\n",
        "    self.prevPosition = self.position\n",
        "    self.position=self.position+self.velocity*t+(self.acceleration/2)* t**2\n",
        "  \n",
        "  # update velocity\n",
        "  def setVelocity(self,t):\n",
        "    self.velocity=self.velocity+self.acceleration*t\n",
        "  \n",
        "  # get force\n",
        "  def getForce(self,body):\n",
        "    softening = 0.01\n",
        "    Distance = body.prevPosition - self.position\n",
        "    Rsquare = Distance[0]**2 + Distance[1]**2 #+ softening\n",
        "  # F = G* self.mass*body.mass / Rsquare  \n",
        "    F = (G* self.mass*body.mass / Rsquare) - 0.001 / (Rsquare * Rsquare) ### Lennard-Jones like force\n",
        "    normalizeDis = Distance / math.sqrt(Rsquare)\n",
        "    F = F*normalizeDis\n",
        "  # if math.sqrt(Rsquare) < softening:\n",
        "    #  F = -F \n",
        "    return F\n",
        "\n",
        "  # update acceleration\n",
        "  def setAcceleration(self,bodies):\n",
        "    F=np.array([0,0])\n",
        "    for body in bodies:\n",
        "      F=F+self.getForce(body)\n",
        "    self.acceleration = F/self.mass\n",
        "   # print(f\" {self.name} acceleration is {self.acceleration}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVFZB6lCsRDZ"
      },
      "source": [
        "#### Aditional Body functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrFfMcZdslXl"
      },
      "source": [
        "calculate the center of mass of the generated bodies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PA_9ROZZr08h"
      },
      "outputs": [],
      "source": [
        "# return the center of mass of the bodies\n",
        "def centerOfMass(bodies):\n",
        "  out =np.array([0,0])\n",
        "  for i in range(0,len(bodies),2):\n",
        "    out = out + np.array(bodies[i],bodies[i+1])\n",
        "  return out / (len(bodies)//2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ahEHdGmkEQLO"
      },
      "outputs": [],
      "source": [
        "# initialize bodies\n",
        "def initialize_bodies(bodylist):\n",
        "  bodies=[]\n",
        "  for i,body in enumerate(bodylist):\n",
        "    bodies.append(Body(body[0],body[1],1,\"body\"+str(i+1)))\n",
        "  return bodies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVi0--xj_sRe"
      },
      "source": [
        "### Double Pendulum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbMNN3KUEpjp"
      },
      "source": [
        "#### The Double Pendulum Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rHKFVlvpUETV"
      },
      "outputs": [],
      "source": [
        "from numpy import sin, cos\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "\n",
        "G_dp = 9.8  # acceleration due to gravity, in m/s^2\n",
        "\n",
        "class double_pendulum:\n",
        "  # variables\n",
        "  length = np.array([0,0])\n",
        "  total_length = 0\n",
        "  mass = np.array([0,0])\n",
        "  angle = np.array([0,0])\n",
        "  angular_velocity = np.array([0,0])\n",
        "  state = np.radians([0, 0, 0, 0])\n",
        "\n",
        "  # constructor\n",
        "  def __init__(self,length=[1,1],mass=[1,1],angle=[120.0,-10.0],angular_velocity=[0,0],name=\"newDoublePendulum\"):\n",
        "    self.length=np.array(length)\n",
        "    self.total_length = length[0] + length[1]\n",
        "    self.mass=np.array(mass)\n",
        "    self.angle=np.array(angle)\n",
        "    self.angular_velocity=np.array(angular_velocity)\n",
        "    self.state = np.radians([angle[0],angular_velocity[0],angle[1],angular_velocity[1]])\n",
        "    self.name = name\n",
        "\n",
        "  def get_pendulum(self,pendulum_id):\n",
        "    return [self.length[pendulum_id],self.mass[pendulum_id],self.angle[pendulum_id],self.angular_velocity[pendulum_id]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu8fN5VqLttI"
      },
      "source": [
        "#### Aditional pendulum functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "TRSzm-PUMFcC"
      },
      "outputs": [],
      "source": [
        "# calculate derivatives\n",
        "def derivs(state,L1,M1,L2,M2):\n",
        "  \n",
        "  dydx = np.zeros_like(state)\n",
        "\n",
        "  dydx[0] = state[1]\n",
        "\n",
        "  delta_deg = state[2] - state[0]\n",
        "  den1 = (M1+M2) * L1 - M2 * L1 * cos(delta_deg) * cos(delta_deg)\n",
        "  dydx[1] = ((M2 * L1 * state[1] * state[1] * sin(delta_deg) * cos(delta_deg)\n",
        "              + M2 * G_dp * sin(state[2]) * cos(delta_deg)\n",
        "              + M2 * L2 * state[3] * state[3] * sin(delta_deg)\n",
        "              - (M1+M2) * G_dp * sin(state[0]))\n",
        "              / den1)\n",
        "\n",
        "  dydx[2] = state[3]\n",
        "\n",
        "  den2 = (L2/L1) * den1\n",
        "  dydx[3] = ((- M2 * L2 * state[3] * state[3] * sin(delta_deg) * cos(delta_deg)\n",
        "              + (M1+M2) * G_dp * sin(state[0]) * cos(delta_deg)\n",
        "              - (M1+M2) * L1 * state[1] * state[1] * sin(delta_deg)\n",
        "              - (M1+M2) * G_dp * sin(state[2]))\n",
        "              / den2)\n",
        "\n",
        "  return dydx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "K1zMHhKSMJ9D"
      },
      "outputs": [],
      "source": [
        "# integrate the Ordinary Differential Equation (ODE) using Euler's method\n",
        "def integrate_ODE(timesteps,dt,pendulum):\n",
        "  inner_pendulum = pendulum.get_pendulum(0)\n",
        "  outer_pendulum = pendulum.get_pendulum(1)\n",
        "  L1 = inner_pendulum[0]\n",
        "  M1 = inner_pendulum[1]\n",
        "  L2 = outer_pendulum[0]\n",
        "  M2 = outer_pendulum[1]\n",
        "\n",
        "  y = np.empty((len(timesteps), 4))\n",
        "  y[0] = pendulum.state\n",
        "  for i in range(1, len(timesteps)):\n",
        "      y[i] = y[i - 1] + derivs(y[i - 1],L1,M1,L2,M2) * dt\n",
        "  return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awqzzi6VsuS8"
      },
      "source": [
        "### General simulation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IntMxz4cvFIz"
      },
      "source": [
        "#### Calculate Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "-uQmZ1gusv7V"
      },
      "outputs": [],
      "source": [
        "# calculate body simulation\n",
        "def simulate_on_time_step(bodies,t,steps,interval_in_data): # bodies: list of bodies. t: timestep . steps: number of steps. interval_in_data : frequency of rows taken to dataset: if equals 1 than it is every step\n",
        "  dataset = []\n",
        "  global runTime_simulation\n",
        "  for i in range(steps):\n",
        "      bodies_pos=[]\n",
        "      for body in bodies:\n",
        "        bodies_pos.append(body.position)\n",
        "      if i % interval_in_data == 0:\n",
        "        dataset += bodies_pos\n",
        "      \n",
        "      for i,body in enumerate(bodies):\n",
        "        body.setAcceleration([b for b in bodies if b is not body])\n",
        "        body.setVelocity(t)\n",
        "        body.setPosition(t)\n",
        "       \n",
        "      for body in bodies:\n",
        "        body.prevPosition = body.position\n",
        "    \n",
        "  three_body_simulation = np.array(dataset).reshape(steps//interval_in_data,len(bodies),2)\n",
        "  three_body_simulation = three_body_simulation.reshape(len(three_body_simulation), len(bodies)*2)\n",
        "  runTime_simulation = three_body_simulation\n",
        "  return runTime_simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "qdxbjwF3UsbY"
      },
      "outputs": [],
      "source": [
        "# calculate pendulum simulation\n",
        "def simulate_double_pendulum(pendulum,timestep=0.01,simulation_time=10):\n",
        "  global runTime_simulation\n",
        "  total_length = pendulum.total_length\n",
        "  inner_pendulum = pendulum.get_pendulum(0)\n",
        "  outer_pendulum = pendulum.get_pendulum(1)\n",
        "\n",
        "  # build array of timesteps [0,timestep,2*timestep,...,simulation_time-timestep]\n",
        "  timesteps = np.arange(0, simulation_time, timestep)\n",
        "\n",
        "  # integrate the ordinary differential equations\n",
        "  y = integrate_ODE(timesteps,timestep,pendulum)\n",
        "\n",
        "  # calculate pendulum positions\n",
        "  x1 = inner_pendulum[0]*sin(y[:, 0])\n",
        "  y1 = -inner_pendulum[0]*cos(y[:, 0])\n",
        "\n",
        "  x2 = outer_pendulum[0]*sin(y[:, 2]) + x1\n",
        "  y2 = -outer_pendulum[0]*cos(y[:, 2]) + y1\n",
        "\n",
        "  double_pendulum_simulation = np.transpose(np.array([x1,y1,x2,y2]))\n",
        "  runTime_simulation = double_pendulum_simulation\n",
        "  return runTime_simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJs0BiCk5bc8"
      },
      "source": [
        "#### Create Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "le7-QJpB5eZA"
      },
      "outputs": [],
      "source": [
        "# create random body simulation\n",
        "def createRandomSimulation(numOfBodies,timestep,steps,interval_in_data=1):\n",
        "  bodies =[]\n",
        "  for i in range(numOfBodies):\n",
        "    bodies.append( Body( np.array([np.random.uniform(-1,1),np.random.uniform(-1,1)]), np.array([np.random.uniform(-1,1) , np.random.uniform(-1,1)]) , 1 ) )\n",
        "\n",
        "  simulation = simulate_on_time_step(bodies,timestep,steps,interval_in_data)\n",
        "  simulation=simulation.reshape(len(simulation), numOfBodies*2 )\n",
        "  return simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8UR-T3DyYyE"
      },
      "source": [
        "#### Display Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZoZH2AzWybUA"
      },
      "outputs": [],
      "source": [
        "# display the simulation (image)\n",
        "import anvil.mpl_util\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def drawSimulation(simulation, simulation_name):\n",
        "  prev = np.copy(simulation[0])\n",
        "  numOfBodies = len(simulation[0])\n",
        "  from random import randint\n",
        "  colors = []\n",
        "\n",
        "  for i in range(30):\n",
        "    colors.append('#%06X' % randint(0, 0xFFFFFF))\n",
        "\n",
        "  #colors = ['red','green','blue','yellow','black','brown','purple','pink',]\n",
        "  mpl_fig = plt.figure()\n",
        "  print(type(simulation))\n",
        "  print(simulation)\n",
        "  for i,sim in enumerate(simulation):\n",
        "    #if i == 0:\n",
        "      #continue\n",
        "    for j in range(0,len(sim),2):\n",
        "      plt.plot([prev[j],sim[j]],[prev[j+1],sim[j+1]],  color = colors[j // 2])\n",
        "      prev[j] = np.copy(sim[j])\n",
        "      prev[j+1] = np.copy(sim[j+1])\n",
        "\n",
        "  plt.savefig(f\"/content/tmp/{simulation_name}\")\n",
        "  img = Image.open(f\"/content/tmp/{simulation_name}.png\",mode='r')\n",
        "  bs = io.BytesIO()\n",
        "  img.save(bs,format=\"PNG\")\n",
        "  return anvil.BlobMedia(\"image/png\", bs.getvalue(), name=simulation_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "9AmQUn2zy2aF"
      },
      "outputs": [],
      "source": [
        "# display body movment (image)\n",
        "def showBodiesMovmentInGraph(simulation):\n",
        "  plt.title(\"X body coordinate\")\n",
        "  for i in range(0,len(simulation.columns),2):\n",
        "      df = simulation.iloc[:,i]\n",
        "      plt.plot(df)\n",
        "  plt.show()\n",
        "  plt.title(\"Y body coordinate\")\n",
        "  for i in range(1,len(simulation.columns),2):\n",
        "      df = simulation.iloc[:,i]\n",
        "      plt.plot(df)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4p6WI69p5tF"
      },
      "source": [
        "### File Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "HbJchCHOHsux"
      },
      "outputs": [],
      "source": [
        "# create temp folder\n",
        "import os\n",
        "\n",
        "@anvil.server.callable\n",
        "def create_tmp_folder():\n",
        "  path = os.path.join('/content/', 'tmp')\n",
        "  if os.path.exists(path):\n",
        "    return\n",
        "  os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "4ADZv93PK1Ss"
      },
      "outputs": [],
      "source": [
        "# remove temp folder\n",
        "import shutil\n",
        "\n",
        "@anvil.server.callable\n",
        "def remove_tmp_folder():\n",
        "  dir_path = '/content/tmp'\n",
        "  shutil.rmtree(dir_path, ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "v8BN_RwwZhqh"
      },
      "outputs": [],
      "source": [
        "remove_tmp_folder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "aZr4gqdevRPa"
      },
      "outputs": [],
      "source": [
        "# save current simulation as a .csv file\n",
        "def saveSimulation(simulation,numOfBodies,simulation_name):\n",
        "  df = numpyToPandas(simulation,numOfBodies)\n",
        "  df.to_csv(f'/content/tmp/{simulation_name}.csv',index=False)\n",
        "  \n",
        "# load simulation from a .csv file\n",
        "def loadSimulation(df):\n",
        "  global runTime_simulation\n",
        "  runTime_simulation = pd.DataFrame.to_numpy(df)\n",
        "  return runTime_simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "pRro_L7zoYFg"
      },
      "outputs": [],
      "source": [
        "import anvil.media\n",
        "\n",
        "# transfer a saved .csv file from colab to anvil\n",
        "@anvil.server.callable\n",
        "def get_sim_csv(simulation_name):\n",
        "  f = open(f'/content/tmp/{simulation_name}.csv', 'r')\n",
        "  data = f.read().encode('utf_8')\n",
        "  return anvil.BlobMedia(\"text/csv\", data , name=simulation_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "t2dF8Mmj5n7O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# transfer a loaded .csv file from anvil to colab\n",
        "@anvil.server.callable\n",
        "def store_data(file,file_name):\n",
        "  with anvil.media.TempFile(file) as f:\n",
        "    df = pd.read_csv(f)\n",
        "    df.to_csv(f'/content/tmp/{file_name}.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqlyhXSzusJ1"
      },
      "source": [
        "#### Simulation Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "61n0yJswuwVj"
      },
      "outputs": [],
      "source": [
        "# Add random noise to the simulation\n",
        "def addNoise(simulation):\n",
        "  noise = np.random.normal(0, .1, simulation.shape)\n",
        "  return simulation + noise\n",
        "\n",
        "# Remove a body from the simulation\n",
        "def removeBody(simulation, bodyNum):\n",
        "  del1 = np.delete(simulation,(bodyNum-1)*2,1)\n",
        "  return np.delete(del1,(bodyNum-1)*2,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSXRZnyRuVgu"
      },
      "source": [
        "### Additional functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "S3_eVXIVuYVn"
      },
      "outputs": [],
      "source": [
        "# convert simulation to fit panda's format\n",
        "def numpyToPandas(simulation,numOfBodies):\n",
        "  columns = []\n",
        "\n",
        "  for i in range(numOfBodies):\n",
        "    columns.append(f'Body{i+1} x')\n",
        "    columns.append(f'Body{i+1} y')\n",
        "  simulation_reshaped = simulation.reshape(len(simulation), numOfBodies*2 )\n",
        "\n",
        "  df = pd.DataFrame(simulation_reshaped, columns = columns)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "nzLeXovM4YjI"
      },
      "outputs": [],
      "source": [
        "# preprocess simulation\n",
        "def preprocessSimulation(simulation):\n",
        "  shape = simulation[0].shape\n",
        "  newSimulation = np.append(simulation[1:],[np.zeros(shape)],axis=0) - simulation\n",
        "  newSimulation = newSimulation[:-1]\n",
        "  for i,s in enumerate(newSimulation):\n",
        "    s = s / np.linalg.norm(simulation[i])\n",
        "  return newSimulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVonAV0Ins_1"
      },
      "source": [
        "### Anvil - simulation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "IJcOTxi2fjvk"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def make_body_simulation(simulation_name,bodylist,timesteps,steps,interval_in_data):\n",
        "  bodies = initialize_bodies(bodylist)\n",
        "  sim = simulate_on_time_step(bodies,timesteps,steps,interval_in_data)\n",
        "  saveSimulation(sim,len(bodylist),simulation_name)\n",
        "  #showBodiesMovmentInGraph(sim).show()\n",
        "  return drawSimulation(sim,simulation_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "5bYqWUfWDpzc"
      },
      "outputs": [],
      "source": [
        "# create pendulum simulation\n",
        "@anvil.server.callable\n",
        "def make_pendulum_simulation(simulation_name,doublePendulum,simulation_time,timestep):\n",
        "  inner_pendulum = doublePendulum[0]\n",
        "  outer_pendulum = doublePendulum[1]\n",
        "  pendulum = double_pendulum([inner_pendulum[0],outer_pendulum[0]],[inner_pendulum[1],outer_pendulum[1]],\n",
        "                             [inner_pendulum[2],outer_pendulum[2]],[inner_pendulum[3],outer_pendulum[3]],\n",
        "                             simulation_name)\n",
        "  sim = simulate_double_pendulum(pendulum,timestep,simulation_time)\n",
        "  saveSimulation(sim,2,simulation_name)\n",
        "  return drawSimulation(sim,simulation_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "_b8CiZQdAf1t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import image\n",
        "\n",
        "@anvil.server.callable\n",
        "def make_simulation_from_csv(simulation_name):\n",
        "  df = pd.read_csv(f'/content/tmp/{simulation_name}.csv')\n",
        "  simulation = loadSimulation(df)\n",
        "  return drawSimulation(simulation,simulation_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Xv3dBnv9FV"
      },
      "source": [
        "## Predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmqdpfChwDFv"
      },
      "source": [
        "Prepare Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "R48xKpIavu8L"
      },
      "outputs": [],
      "source": [
        "# prepare simulation for Model training\n",
        "def prepareData(simulation,window_size_X,window_size_y): \n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(simulation)-window_size_X - window_size_y):\n",
        "    row = [bodies for bodies in simulation[i:i+window_size_X]]  \n",
        "    X.append(row)\n",
        "    label =  [bodies for bodies in simulation[i+window_size_X:i+window_size_X + window_size_y]]\n",
        "    y.append(label)\n",
        "\n",
        "  return np.array(X) , np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Od0-lw5xKui"
      },
      "source": [
        "Model Pre-Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "vnXlIKalwNLu"
      },
      "outputs": [],
      "source": [
        "# create random training set\n",
        "def createRandomTrainingSetForPreTrainedModel():\n",
        "    randomSimulations = []\n",
        "    numOfSimulations = 5\n",
        "    X_trainArr = [None]*numOfSimulations\n",
        "    y_trainArr = [None]*numOfSimulations\n",
        "    for i in range(numOfSimulations):\n",
        "      randomSimulations.append(createRandomSimulation(4,timestep,steps,interval_in_data))\n",
        "      X_trainArr[i], y_trainArr[i] = prepareData(train,windowSizeX,windowSizeY)\n",
        "\n",
        " #   for i in range(len(randomSimulations)):\n",
        "      saveSimulation(randomSimulations[i],numOfBodies,f\"{numOfBodies}-Body Simulation{i+20}\")\n",
        "\n",
        "\n",
        "    return X_trainArr, y_trainArr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "bfdGlQAtxBd-"
      },
      "outputs": [],
      "source": [
        "# train model on random simulation\n",
        "def trainOnRandomSimulations(epochs, numOfSimulations, X_trainArr,y_trainArr):\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for j in range(numOfSimulations):\n",
        "      #model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, callbacks=[cp1])\n",
        "      #history = model.fit(X_train, y_train, epochs=1, callbacks=[cp1])\n",
        "        history = model.fit(X_trainArr[i], y_trainArr[i], epochs=1, callbacks=[cp1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "OQ2igit9zOqj"
      },
      "outputs": [],
      "source": [
        "### Inception\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def inception_module(x, base_channels=32):\n",
        "  #a = Conv2D(base_channels*2, 1, 1, activation='relu')(x)\n",
        "  \n",
        "  \n",
        "  b_1 = Conv2D(base_channels*2, 3, 1, activation='relu')(x)\n",
        "  b_2 = Conv2D(base_channels*4, 3, 1, padding='same', activation='relu')(b_1)\n",
        "\n",
        "  c_1 = Conv2D(base_channels, 3, 1, activation='relu')(x)\n",
        "  c_2 = Conv2D(base_channels, 5, 1, padding='same', activation='relu')(c_1)\n",
        "\n",
        "\n",
        "  d_1 = MaxPooling2D(3, 1, padding='same')(x)\n",
        "  d_2 = Conv2D(base_channels, 1, 1, activation='relu')(d_1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return Concatenate(axis=-1)([b_2, c_2])\n",
        "\n",
        "def Inceptionmodel(window_size_X,window_size_y,numberOfBodies):\n",
        "\n",
        "  inp = Input((window_size_X, numberOfBodies*2, 1))\n",
        "\n",
        "  maps_1 = inception_module(inp)\n",
        "  maps_2 = inception_module(maps_1, base_channels=16)\n",
        "  \n",
        "  #gap = GlobalMaxPooling2D()(maps_2)\n",
        "  flatten = Flatten()(maps_2)\n",
        "\n",
        "  output = Dense(window_size_y * numberOfBodies*2, activation='linear')(flatten)\n",
        "  output = (tf.keras.layers.Reshape([window_size_y, numberOfBodies*2]))(output)\n",
        "  model = Model(inputs=inp, outputs=output)\n",
        "  model.summary()\n",
        "  return model\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnj3S6dXyGNt"
      },
      "source": [
        "Split Simulation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "IJHdfzYsxlDx"
      },
      "outputs": [],
      "source": [
        "# split simulation data to training, validation & testing sets\n",
        "def splitToTrainValidTest(simulation,testPercentage=0.1):\n",
        "  trainLen = round((len(simulation)*(1-testPercentage-0.1)))\n",
        "  valLen = round((len(simulation)*0.1))\n",
        "  train_set = simulation[:trainLen]\n",
        "  val_set = simulation[trainLen:trainLen+valLen]\n",
        "  test_set = simulation[trainLen+valLen:]\n",
        "  return train_set,val_set,test_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9mg1vx1z-FV"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "-Xwr50CtZXGS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6hiOgDwzbuR"
      },
      "source": [
        "#### CNN (Convolutional Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "DN6zzPFqY9sC"
      },
      "outputs": [],
      "source": [
        "def buildModelCNN(window_size_X,window_size_y,numberOfBodies): \n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((window_size_X,numberOfBodies*2,1)))\n",
        "\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(units =  window_size_y*numberOfBodies*2, activation ='linear'))\n",
        "    model.add(tf.keras.layers.Reshape([window_size_y, numberOfBodies*2]))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIf1vtvq0CCH"
      },
      "source": [
        "#### LSTM (Long Short-Term Memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ah9d8FiMY9sC"
      },
      "outputs": [],
      "source": [
        "def buildModelLSTM(window_size_X,window_size_y,numberOfBodies):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.LSTM(128, kernel_initializer='he_uniform', batch_input_shape=(None, window_size_X, numberOfBodies*2), return_sequences=True, name='encoder_1'))\n",
        "  model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))\n",
        "  model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_3'))\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(units =  window_size_y*numberOfBodies*2, activation ='linear'))\n",
        "  model.add(tf.keras.layers.Reshape([window_size_y, numberOfBodies*2]))\n",
        "  model.summary()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoVRzkm-0n2Z"
      },
      "source": [
        "#### GRU (Gated Recurrent Unit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "cipbsXk8aFmr"
      },
      "outputs": [],
      "source": [
        "def buildModelGRU(window_size_X,window_size_y,numberOfBodies):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.GRU(128, kernel_initializer='he_uniform', batch_input_shape=(None, window_size_X, numberOfBodies*2), return_sequences=True, name='encoder_1'))\n",
        "  model.add(keras.layers.GRU(64, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))\n",
        "  model.add(keras.layers.GRU(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_3'))\n",
        "\n",
        "  model.add(Dense(units =  window_size_y*numberOfBodies*2, activation ='linear'))\n",
        "  model.add(tf.keras.layers.Reshape([window_size_y, numberOfBodies*2]))\n",
        "  model.summary()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhd1anGE2d52"
      },
      "source": [
        "### Model Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmTt-V66CCQg"
      },
      "source": [
        "#### Display Model Prediction + Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "56ZQqMQHnBgZ"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def make_model(model_type,windowSizeX=100,windowSizeY=100):\n",
        "  global runTime_model\n",
        "  global runTime_simulation\n",
        "  global history\n",
        "\n",
        "  global X_train\n",
        "  global y_train\n",
        "  global X_val\n",
        "  global y_val\n",
        "  global X_test\n",
        "  global y_test\n",
        "\n",
        "  numOfBodies = runTime_simulation.shape[1]//2\n",
        "  # diffSimulation1 = np.diff(runTime_simulation,axis = 0)\n",
        "  train,val,test = splitToTrainValidTest(runTime_simulation,0.4)\n",
        " \n",
        "  X_train,y_train = prepareData(train, windowSizeX,windowSizeY)\n",
        "  X_val,y_val = prepareData(val, windowSizeX,windowSizeY)\n",
        "  X_test,y_test = prepareData(test, windowSizeX,windowSizeY)\n",
        "\n",
        "  if model_type == \"LSTM\":\n",
        "    runTime_model = buildModelLSTM(windowSizeX,windowSizeY,numOfBodies)\n",
        "  if model_type == \"GRU\":\n",
        "    runTime_model = buildModelGRU(windowSizeX,windowSizeY,numOfBodies)\n",
        "  if model_type == \"CNN\":\n",
        "    runTime_model = buildModelCNN(windowSizeX,windowSizeY,numOfBodies)\n",
        "\n",
        "  cp1 = ModelCheckpoint('runTime_model/', save_best_only=True)\n",
        "  runTime_model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])\n",
        "  history = runTime_model.fit(X_train,y_train, validation_data=(X_val, y_val), epochs=15, callbacks=[cp1],batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ewE1uBCJvZ0u"
      },
      "outputs": [],
      "source": [
        "import anvil.mpl_util\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "@anvil.server.callable\n",
        "def show_loss(simulation_name):\n",
        "\n",
        "  global history\n",
        "  plt.clf()\n",
        "  plt.title('model loss')\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  try:\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "  except:\n",
        "    print(\"not enough data for validation graph\")\n",
        "\n",
        "  plt.savefig(f\"/content/tmp/{simulation_name}_loss\")\n",
        "  img = Image.open(f\"/content/tmp/{simulation_name}_loss.png\",mode='r')\n",
        "  bs = io.BytesIO()\n",
        "  img.save(bs,format=\"PNG\")\n",
        "  return anvil.BlobMedia(\"image/png\", bs.getvalue(), name=simulation_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "tNJDjsGrvyH7"
      },
      "outputs": [],
      "source": [
        "\n",
        "@anvil.server.callable\n",
        "def get_prediction(simulation_name):\n",
        "  global X_test\n",
        "  global predictions\n",
        "  global runTime_model\n",
        "  predictions = runTime_model.predict(X_test[:1])\n",
        "  predictions = predictions.squeeze()\n",
        "  return drawSimulation(predictions,f'{simulation_name}_prediction')\n",
        "\n",
        "@anvil.server.callable\n",
        "def get_real(simulation_name):\n",
        "  global y_test\n",
        "  real = y_test[:1]\n",
        "  real = real.squeeze()\n",
        "  return drawSimulation(real,f'{simulation_name}_real')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmxDombm6wtr"
      },
      "source": [
        "## Anvil connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkvVFILk60pB"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  try:\n",
        "    anvil.server.wait_forever()\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"...disconnected from anvil\")"
      ]
    }
  ]
}